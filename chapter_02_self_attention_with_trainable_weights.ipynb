{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsTZk/8C3wfjXwUP14JlN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nitinyad/LLM-from-scratch/blob/main/chapter_02_self_attention_with_trainable_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing self attention with trainable weights"
      ],
      "metadata": {
        "id": "tq0lJIQjIIDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0Gt2y5XH8e3",
        "outputId": "c361ec0a-03eb-4445-802f-e9668aad2e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 3])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "    [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "    [0.57, 0.85, 0.64], # starts    (x^3)\n",
        "    [0.22, 0.58, 0.33], # with      (x^4)\n",
        "    [0.77, 0.25, 0.10], # one       (x^5)\n",
        "    [0.05, 0.80, 0.55]] # step      (x^6)\n",
        ")\n",
        "print(inputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = inputs[1] # second input element\n",
        "d_in = inputs.shape[1] # the input embedding size , d = 3\n",
        "d_out = 2 # the ouput embedding size , d_out= 2"
      ],
      "metadata": {
        "id": "DHS-rSC-ITLm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the gpt , normally the input and output dimensions are usually same .\n",
        "to just illustrate we are using different dimensions."
      ],
      "metadata": {
        "id": "9rdm1ozRIUR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "initalize three weight matrices , Wq , Wk and Ww"
      ],
      "metadata": {
        "id": "TqfSd2zhIml9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123) # by doing this the same random numbers will be generated every time you run your code.\n",
        "Wq = torch.nn.Parameter(torch.rand(d_in, d_out) , requires_grad=False)\n",
        "Wk = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "Wv = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "i2n0y862IRet"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Wq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jncjWOESJV5P",
        "outputId": "84297123-7642-47ec-80f4-92adf89d0e46"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for now we are setting the requires_grad = False to reduce clutter in the ouputs for illustrations purpose.\n",
        "if we were to use the weight matrices for model training , we would set required_grad = True to update these matrices during model training."
      ],
      "metadata": {
        "id": "9EmomrFxKg3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now , compute query , key and value vector"
      ],
      "metadata": {
        "id": "j6tXeK65LHHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ Wq\n",
        "key_2 = x_2 @ Wk\n",
        "value_2 = x_2 @ Wv\n",
        "print(query_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a49bqFcyLQRm",
        "outputId": "bc302749-c840-4a3c-d993-2ff4ebc23fc2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4306, 1.4551])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see based on the output for the query , this result in 2-dim vector.\n",
        "because we are setting the number of columns of corresponding weights matrix , via d_out to 2"
      ],
      "metadata": {
        "id": "E0ehFBRbMURM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "even though our temporary goal is to only compute the one context vector z(2) we still require the key and value vectors for all inputs elements ,\n",
        "this is because they are involved in computing the attention weights with respect to the query q(2)  "
      ],
      "metadata": {
        "id": "dS91R_SXOFTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can obtain all keys and values via matrix multiplications\n",
        "keys = inputs @ Wk\n",
        "values = inputs @ Wv\n",
        "querys = inputs @ Wq\n",
        "print(\"key.shape\" , keys.shape)\n",
        "print(\"value.shape\" , values.shape)\n",
        "print(\"query.shape\" , querys.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z-bbn9-LkoB",
        "outputId": "bb99a989-7c73-441c-ac3d-4f330b6019bc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key.shape torch.Size([6, 2])\n",
            "value.shape torch.Size([6, 2])\n",
            "query.shape torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can tell from the output , we successfully projected the 6 input tokens from a 3d to 2d embedding inputs;\n"
      ],
      "metadata": {
        "id": "zjBQicmqP0eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key_2 = keys[1]\n",
        "attn_score_22 = query_2.dot(key_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "id": "Z94B3BIrPNc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa99cf30-9c2b-47f9-a87f-f43ee5841462"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "find for all attention scores via matrix multiplication"
      ],
      "metadata": {
        "id": "U5XTxNAALQGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_score_22 = query_2 @ keys.T\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQFz2dgxKxxj",
        "outputId": "1b4b7fc1-2b1b-4c40-95ab-36e9c9e60010"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = querys @ keys.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mewrp015LMrg",
        "outputId": "435b8805-9131-40ab-f2fb-2e3d94c363c8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
            "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
            "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
            "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
            "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
            "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we compute the attention weights by scaling the attention scores and using the softmax function we used earlier.\n",
        "the difference to eariler is that we now scale the attention scores by dividing them by square root of the embedding dimension of the keys."
      ],
      "metadata": {
        "id": "VVsWEjxMN9qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_score_22 / d_k ** 0.5 , dim = -1)\n",
        "print(attn_weights_2)\n",
        "print(d_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnlBEZQRPEkH",
        "outputId": "c7de2021-65da-4655-be30-5cf1e414c6b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## why divide by sqrt (dimension)"
      ],
      "metadata": {
        "id": "5-KfydboSdMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reason 1 : for the stability in learning\n",
        "The softmax function is sensitive to the magnitudes of its inputs. when the inputs are large , the difference between the exponential values of each input become much more pronounced. This causes the softmax output to become 'peaky',where the highest value receives almost all the probability mass , and the rest receive a very little."
      ],
      "metadata": {
        "id": "MdlSf-C-Sj0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
        "\n",
        "softmax_result = torch.softmax(tensor , dim = -1)#softmax without scaling\n",
        "print(\"softmax without scaling , \" , softmax_result)\n",
        "\n",
        "# softmax with scaling , mulitple the tensor with 8\n",
        "scaled_tensor= tensor * 8\n",
        "softmax_scaled_result = torch.softmax(scaled_tensor , dim = -1)\n",
        "print(\"softmax with scaling , \" , softmax_scaled_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bqulHrYTahY",
        "outputId": "03d1aab1-15b5-4427-b2b0-a142b3168f04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax without scaling ,  tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "softmax with scaling ,  tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the attention mechanisms , particularly in transformers, if the dot products between query and key vector become too large (like multipling with 8 ) , the attention scores can become very large. This results in a very sharp softmax distribution , making the model overly confident in one particular \"key\" . such sharp distribution can make learning unstable."
      ],
      "metadata": {
        "id": "L1aEBXePWEDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why sqrt??\n",
        ""
      ],
      "metadata": {
        "id": "qja1xEn9XPPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reason 2: to make the variance of the dot product stable.\n",
        "the dot product of q and k increases the variance because multiplying two random numbers increases the variance .\n",
        "the increase in variance grows with the dimensions.\n",
        "dividing by sqrt(dimension) keeps the variance close to 1."
      ],
      "metadata": {
        "id": "L-DruyYiXUYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the reason why variance should be close to one is that if the variance increase a lot it make the learning very unstable , we don't want that we want to keep the standard deviation and variance close so that learing is stable (don't give random values and it should stay to 1 )\n",
        "\n",
        "and by doing this we are also avoiding the computational issues."
      ],
      "metadata": {
        "id": "A4GuIx_FYzUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_variance(dim , num_trails = 1000):\n",
        "  dot_products = []\n",
        "  scaled_dot_products = []\n",
        "\n",
        "  for _ in range(num_trails):\n",
        "    q = np.random.randn(dim)\n",
        "    k = np.random.randn(dim)\n",
        "\n",
        "    dot_product = np.dot(q, k )\n",
        "    dot_products.append(dot_product)\n",
        "\n",
        "    scaled_dot_product = np.dot(q , k) / np.sqrt(dim)\n",
        "\n",
        "    scaled_dot_products.append(scaled_dot_product)\n",
        "\n",
        "  variance = np.var(dot_products)\n",
        "  scaled_variance = np.var(scaled_dot_products)\n",
        "\n",
        "  return variance , scaled_variance\n",
        "\n",
        "variance_before_5 , variance_after_5 = compute_variance(5)\n",
        "print(\"Variance before scaling (dim = 5 )\" , {variance_before_5})\n",
        "print(\"Variance after scaling (dim = 5 )\" , {variance_after_5})\n",
        "variance_before_100 , variance_after_100 = compute_variance(100)\n",
        "print(\"Variance before scaling (dim = 100 )\" , {variance_before_100})\n",
        "print(\"Variance after scaling (dim = 100 )\" , {variance_after_100})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl1UVnsNW1oL",
        "outputId": "949cff4a-7be7-4c6c-9338-54569ba602c2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance before scaling (dim = 5 ) {np.float64(5.244715543858811)}\n",
            "Variance after scaling (dim = 5 ) {np.float64(1.0489431087717622)}\n",
            "Variance before scaling (dim = 100 ) {np.float64(100.44738499329094)}\n",
            "Variance after scaling (dim = 100 ) {np.float64(1.0044738499329093)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute the context vector"
      ],
      "metadata": {
        "id": "7B05IGYrdaYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "as a weighted sum over the value vectors.\n",
        "here , the attention weights serve as a weighting factor that weights the respective importance of each value vector.\n",
        "\n",
        "we can use matrix multiplication to obtain the output:"
      ],
      "metadata": {
        "id": "_1oCbA_Qi76v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zm4z-hCj5K_",
        "outputId": "e23830d0-f7f3-439e-dc9f-6ea2ca9511a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3061, 0.8210])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## implementing a compact self attention python class"
      ],
      "metadata": {
        "id": "T1mHexf1kGa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "  def __init__(self, d_in , d_out):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in , d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in , d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in , d_out))\n",
        "\n",
        "  def forward(self , x):\n",
        "    key = x @ self.W_key\n",
        "    query = x @ self.W_query\n",
        "    value = x @ self.W_value\n",
        "    attn_scores = query @ key.T\n",
        "    d_k = key.shape[-1]\n",
        "    attn_weights = torch.softmax(attn_scores / (d_k ** 0.5) , dim = -1)\n",
        "    context_vec = attn_weights @ value\n",
        "    return context_vec\n"
      ],
      "metadata": {
        "id": "0CVcHAMUkMZ1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this pytorch code , selfattention v1 is a class derived from nn.Module , which is a fundamental building block of Pytorch model , which provides neccessary functionalities for model layer creation and management.\n",
        "\n",
        "The init method initializes trainable weight matrices (W_query , W_key , W_value) for queries , keys , values , and each transforming the input dimension d_in to an output dimension d_out.\n",
        "\n",
        "using the forward pass method , we compute the attention scores by multipling queries and keys , normalizing these scores using softmax.\n",
        "\n"
      ],
      "metadata": {
        "id": "UWna3ONQna8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in , d_out)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn0SqYgfnYlo",
        "outputId": "83f05371-902c-4906-e572-84c6a662e7df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can improve the selfAttention_V1 implementation further by utilizing pytorch's nn.Linear layers , which effectively perform matrix multiplication when the bias units are disabled."
      ],
      "metadata": {
        "id": "dmJeqdD9x0Pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "advantage of using nn.Linear instead of manually implementing nn.Parameter(torch.randn()) is that nn.Linear has an optimized weight initialized scheme , contributing to more stable and effective model training."
      ],
      "metadata": {
        "id": "aQp-1L2ByNon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "  def __init__(self , d_in , d_out , qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Linear(d_in , d_out , bias = qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in , d_out , bias = qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in , d_out , bias = qkv_bias)\n",
        "  def forward(self , x):\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    attn_scores = queries @ keys.T\n",
        "\n",
        "    attn_weights = torch.softmax(attn_scores / (d_k ** 0.5) , dim = -1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "iN8jjotRyqHd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttention_v2(d_in , d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOmJL_aezE4S",
        "outputId": "efee3374-de3f-46da-fb23-fcd15182fb0d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0739,  0.0713],\n",
            "        [-0.0748,  0.0703],\n",
            "        [-0.0749,  0.0702],\n",
            "        [-0.0760,  0.0685],\n",
            "        [-0.0763,  0.0679],\n",
            "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "both SelfAttention_v1 and selfattention_v2 give different outputs because they use different initial weights for the weight matrices since nn.Linear uses a more sophisticated weight initialized scheme."
      ],
      "metadata": {
        "id": "x30burlZzVq4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xe1wlSCuzufT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}